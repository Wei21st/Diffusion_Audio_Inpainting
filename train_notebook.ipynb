{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "import utils.dnnlib as dnnlib\n",
    "from utils.torch_utils import distributed as dist\n",
    "import utils.setup as setup\n",
    "from training.trainer import Trainer\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_int_list(s):\n",
    "    if isinstance(s, list): return s\n",
    "    ranges = []\n",
    "    range_re = re.compile(r'^(\\d+)-(\\d+)$')\n",
    "    for p in s.split(','):\n",
    "        m = range_re.match(p)\n",
    "        if m:\n",
    "            ranges.extend(range(int(m.group(1)), int(m.group(2))+1))\n",
    "        else:\n",
    "            ranges.append(int(p))\n",
    "    return ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_init_fn(worker_id):\n",
    "    st=np.random.get_state()[2]\n",
    "    np.random.seed( st+ worker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "args = OmegaConf.create({\n",
    "    # Logging --- Base logging\n",
    "    \"logging\": {\n",
    "    \"log\": True,\n",
    "    \"log_interval\": 1000,\n",
    "    \"heavy_log_interval\": 50000,  # same as save_interval\n",
    "    \"save_model\": True,\n",
    "    \"save_interval\": 50000,\n",
    "\n",
    "    \"num_sigma_bins\": 20,\n",
    "    \"freq_cqt_logging\": 100,\n",
    "\n",
    "    \"print_model_summary\": False, ## orginial is True\n",
    "\n",
    "    \"profiling\": {\n",
    "        \"enabled\": True,\n",
    "        \"wait\": 5,\n",
    "        \"warmup\": 10,\n",
    "        \"active\": 2,\n",
    "        \"repeat\": 1\n",
    "    },\n",
    "\n",
    "    \"stft\": {\n",
    "        \"win_size\": 1024,\n",
    "        \"hop_size\": 256\n",
    "    },\n",
    "\n",
    "    \"cqt\": {\n",
    "        \"hop_length\": 1024,\n",
    "        \"num_octs\": 6,\n",
    "        \"fmin\": 70,\n",
    "        \"bins_per_oct\": 1\n",
    "    },\n",
    "\n",
    "    \"log_feature_stats\": True,\n",
    "    \"log_feature_stats_interval\": 50000\n",
    "},\n",
    "    \n",
    "    # Dataset configuration\n",
    "    \"dset\": {\n",
    "        \"name\": \"musicnet\",\n",
    "        \"callable\": \"datasets.audiofolder.AudioFolderDataset\",\n",
    "        \"path\": r\"E:\\Class\\ECE661\\audio-inpainting-diffusion\\musicnet\\train_data\",\n",
    "\n",
    "        \"test\": {\n",
    "            \"callable\": \"datasets.audiofolder_test.AudioFolderDatasetTest\",\n",
    "            \"num_samples\": 4,\n",
    "            \"batch_size\": 1,\n",
    "            \"path\": r\"E:\\Class\\ECE661\\audio-inpainting-diffusion\\musicnet\\test_data\",\n",
    "        },\n",
    "    },\n",
    "\n",
    "    # Network configuration\n",
    "    \"network\": {\n",
    "        \"name\": \"unet_cqt_oct_with_attention\",  # adaLN_2\n",
    "        \"callable\": \"networks.unet_cqt_oct_with_projattention_adaLN_2.Unet_CQT_oct_with_attention\",\n",
    "\n",
    "        \"use_fencoding\": False,\n",
    "        \"use_norm\": True,\n",
    "        \"filter_out_cqt_DC_Nyq\": True,\n",
    "\n",
    "        \"depth\": 7,\n",
    "        \"emb_dim\": 256,\n",
    "\n",
    "        \"Ns\": [64,96, 96, 128, 128,256, 256],\n",
    "        \"Ss\": [2, 2, 2, 2, 2, 2, 2],\n",
    "        \"num_dils\": [2,3,4,5,6,7,7],\n",
    "\n",
    "        \"attention_layers\": [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "        \"bottleneck_type\": \"res_dil_convs\",\n",
    "        \"num_bottleneck_layers\": 1,\n",
    "\n",
    "        \"cqt\": {\n",
    "            \"window\": \"kaiser\",\n",
    "            \"beta\": 1,\n",
    "            \"num_octs\": 7,\n",
    "            \"bins_per_oct\": 64,\n",
    "        },\n",
    "\n",
    "        \"attention_dict\": {\n",
    "            \"num_heads\": 8,\n",
    "            \"attn_dropout\": 0.0,\n",
    "            \"bias_qkv\": False,\n",
    "            \"N\": 0,\n",
    "            \"rel_pos_num_buckets\": 32,\n",
    "            \"rel_pos_max_distance\": 64,\n",
    "            \"use_rel_pos\": False,\n",
    "            \"Nproj\": 8,\n",
    "        }\n",
    "\n",
    "        # Optional transformer block (uncomment if needed)\n",
    "        # \"transformer\": {\n",
    "        #     \"num_heads\": 8,\n",
    "        #     \"dim_head\": 64,\n",
    "        #     \"num_layers\": 16,\n",
    "        #     \"channels\": 512,\n",
    "        #     \"attn_dropout\": 0.1,\n",
    "        #     \"multiplier_ff\": 4,\n",
    "        #     \"activation\": \"gelu\",\n",
    "        # }\n",
    "    },\n",
    "\n",
    "    # Diffusion parameters\n",
    "    \"diff_params\": {\n",
    "        \"callable\": \"diff_params.edm.EDM\",\n",
    "        \"sigma_data\": 0.063,\n",
    "        \"sigma_min\": 1e-5,\n",
    "        \"sigma_max\": 10,\n",
    "        \"P_mean\": -1.2,\n",
    "        \"P_std\": 1.2,\n",
    "        \"ro\": 13,\n",
    "        \"ro_train\": 10,\n",
    "        \"Schurn\": 5,\n",
    "        \"Snoise\": 1,\n",
    "        \"Stmin\": 0,\n",
    "        \"Stmax\": 50,\n",
    "        \"aweighting\": {\n",
    "            \"use_aweighting\": False,\n",
    "            \"ntaps\": 101\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # Tester configuration  \n",
    "    # here use inpainting_tester\n",
    "    \"tester\": {\n",
    "    \"do_test\": True,\n",
    "    \"name\": \"inpainting_tester\",\n",
    "    \"callable\": \"testing.tester_inpainting.Tester\",\n",
    "    \"sampler_callable\": \"testing.edm_sampler_inpainting.Sampler\",\n",
    "\n",
    "    \"modes\": [\"inpainting\"],\n",
    "\n",
    "    \"T\": 35,\n",
    "    \"order\": 2,\n",
    "    \"filter_out_cqt_DC_Nyq\": True,\n",
    "    \"checkpoint\": \"experiments/54/22k_8s-790000.pt\",\n",
    "\n",
    "    \"unconditional\": {\n",
    "        \"num_samples\": 4,\n",
    "        \"audio_len\": 184184\n",
    "    },\n",
    "\n",
    "    \"posterior_sampling\": {\n",
    "        \"xi\": 0.25,\n",
    "        \"norm\": 2,\n",
    "        \"smoothl1_beta\": 1\n",
    "    },\n",
    "\n",
    "    \"data_consistency\": {\n",
    "        \"use\": True,\n",
    "        \"type\": \"always\",\n",
    "        \"smooth\": True,\n",
    "        \"hann_size\": 50\n",
    "    },\n",
    "\n",
    "    \"diff_params\": {\n",
    "        \"same_as_training\": False,\n",
    "        \"sigma_data\": 0.063,\n",
    "        \"sigma_min\": 1e-4,\n",
    "        \"sigma_max\": 1,\n",
    "        \"P_mean\": -1.2,\n",
    "        \"P_std\": 1.2,\n",
    "        \"ro\": 13,\n",
    "        \"ro_train\": 13,\n",
    "        \"Schurn\": 10,\n",
    "        \"Snoise\": 1.0,\n",
    "        \"Stmin\": 0,\n",
    "        \"Stmax\": 50\n",
    "    },\n",
    "\n",
    "    \"autoregressive\": {\n",
    "        \"overlap\": 0.25,\n",
    "        \"num_samples\": 4\n",
    "    },\n",
    "\n",
    "    \"sampler\": \"stochastic\",\n",
    "    \"noise_in_observations_SNR\": None,\n",
    "\n",
    "    \"inpainting\": {\n",
    "        \"mask_mode\": \"long\",\n",
    "        \"long\": {\n",
    "            \"gap_length\": 1500,\n",
    "            \"start_gap_idx\": None\n",
    "        },\n",
    "        \"short\": {\n",
    "            \"num_gaps\": 4,\n",
    "            \"gap_length\": 25,\n",
    "            \"start_gap_idx\": None\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"spectrogram_inpainting\": {\n",
    "        \"stft\": {\n",
    "            \"window\": \"hann\",\n",
    "            \"n_fft\": 1024,\n",
    "            \"hop_length\": 256,\n",
    "            \"win_length\": 1024\n",
    "        },\n",
    "        \"time_mask_length\": 2000,\n",
    "        \"time_start_idx\": None,\n",
    "        \"min_masked_freq\": 300,\n",
    "        \"max_masked_freq\": 2000\n",
    "    },\n",
    "\n",
    "    \"STN_inpainting\": {\n",
    "        \"STN_params\": {\n",
    "            \"nwin1\": 4096,\n",
    "            \"G1\": 0.65,\n",
    "            \"G2\": 0.7\n",
    "        },\n",
    "        \"type\": \"T\"\n",
    "    },\n",
    "\n",
    "    \"comp_sens\": {\n",
    "        \"percentage\": 5\n",
    "    },\n",
    "\n",
    "    \"max_thresh_grads\": 1,\n",
    "    \"type_spec\": \"linear\",\n",
    "\n",
    "    \"declipping\": {\n",
    "        \"SDR\": 3\n",
    "    }\n",
    "},\n",
    "    \n",
    "    # Experiment configuration\n",
    "    \"exp\": {\n",
    "        \"exp_name\": \"musicnet44k_4s_Duke\",\n",
    "        \"trainer_callable\": \"training.trainer.Trainer\",\n",
    "        \"model_dir\": None,\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"adam\", \n",
    "            \"beta1\": 0.9,\n",
    "            \"beta2\": 0.999,\n",
    "            \"eps\": 1e-8\n",
    "        },\n",
    "\n",
    "        \"wandb\": {\n",
    "            \"entity\": \"eloimoliner\",\n",
    "            \"project\": \"A-diffusion\"\n",
    "        },\n",
    "        \"lr\": 2e-4,\n",
    "        \"lr_rampup_it\": 10000,\n",
    "        \"scheduler_step_size\": 60000,\n",
    "        \"scheduler_gamma\": 0.8,\n",
    "        \"batch\": 4,\n",
    "        \"batch_gpu\": 4,\n",
    "        \"num_accumulation_rounds\": 1,\n",
    "        \"use_fp16\": False,\n",
    "        \"num_workers\": 4,\n",
    "        \"seed\": 42,\n",
    "        \"resume\": True,\n",
    "        \"resume_checkpoint\": None,\n",
    "        \"sample_rate\": 44100,\n",
    "        \"audio_len\": 184184,\n",
    "        \"resample_factor\": 1,\n",
    "        \"device\": \"cpu\",\n",
    "        \"use_cqt_DC_correction\": False,\n",
    "        \"ema_rate\": 0.9999,\n",
    "        \"ema_rampup\": 10000,\n",
    "        \"use_grad_clip\": True,\n",
    "        \"max_grad_norm\": 1,\n",
    "        \"restore\": False,\n",
    "        \"checkpoint_id\": None,\n",
    "        \"augmentations\": {\n",
    "            \"rev_polarity\": True,\n",
    "            \"pitch_shift\": {\n",
    "                \"use\": False,\n",
    "                \"min_semitones\": -6,\n",
    "                \"max_semitones\": 6\n",
    "            },\n",
    "            \"gain\": {\n",
    "                \"use\": False,\n",
    "                \"min_db\": -3,\n",
    "                \"max_db\": 3\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory: e:\\Class\\ECE661\\audio-inpainting-diffusion\\experiments/cqt\n"
     ]
    }
   ],
   "source": [
    "# Setup model directory\n",
    "dirname = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "args.model_dir = os.path.join(dirname, str(args.model_dir))\n",
    "if not os.path.exists(args.model_dir):\n",
    "    os.makedirs(args.model_dir)\n",
    "args.exp.model_dir = args.model_dir\n",
    "\n",
    "print(f\"Model directory: {args.model_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup multiprocessing\n",
    "torch.multiprocessing.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dataset path\n",
    "# this is just to make sure you change the path in the args. LOL\n",
    "import glob\n",
    "import random\n",
    "import soundfile as sf\n",
    "\n",
    "path = args.dset.path\n",
    "filelist=glob.glob(os.path.join(path,\"*.wav\"))\n",
    "num=1\n",
    "#for file in self.train_samples:  \n",
    "file=filelist[num]\n",
    "data, samplerate = sf.read(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added e:\\Class\\ECE661\\audio-inpainting-diffusion to Python path\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root directory to Python path\n",
    "project_root = os.path.abspath(os.path.dirname('__file__'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    print(f\"Added {project_root} to Python path\")\n",
    "\n",
    "sys.path.append(r\"E:\\Class\\ECE661\\audio-inpainting-diffusion\\datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training dataset\n",
    "from audiofolder import AudioFolderDataset\n",
    "dset_obj = AudioFolderDataset(dset_args=args.dset, fs=args.exp.sample_rate*args.exp.resample_factor, seg_len=args.exp.audio_len*args.exp.resample_factor, overfit=False)\n",
    "\n",
    "# it has an __iter__ method\n",
    "# it will return a random batch of audio samples with length 4.17 seconds -- or 184184 samples.\n",
    "train_set = iter(torch.utils.data.DataLoader(dataset=dset_obj, \n",
    "                                        batch_size=args.exp.batch,  \n",
    "                                        num_workers=args.exp.num_workers, \n",
    "                                        pin_memory=True, worker_init_fn=worker_init_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusion parameters setup complete\n"
     ]
    }
   ],
   "source": [
    "# set up diff model\n",
    "from diff_params.edm import EDM\n",
    "diff_parameters=EDM(args)\n",
    "print(\"Diffusion parameters setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using a kaiser window with beta= 1\n",
      "Attention layer at (down) octave 4\n",
      "Attention layer at (down) octave 5\n",
      "Attention layer at (down) octave 6\n",
      "Attention layer at (up) oct layer 6\n",
      "Attention layer at (up) oct layer 5\n",
      "Attention layer at (up) oct layer 4\n",
      "Network setup complete\n"
     ]
    }
   ],
   "source": [
    "# Setup network\n",
    "from networks.unet_cqt_oct_with_projattention_adaLN_2 import Unet_CQT_oct_with_attention\n",
    "network = Unet_CQT_oct_with_attention(args, device)\n",
    "print(\"Network setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer setup complete\n"
     ]
    }
   ],
   "source": [
    "# Setup optimizer\n",
    "optimizer = torch.optim.Adam(network.parameters(), \n",
    "                             lr=args.exp.lr, \n",
    "                             betas=(args.exp.optimizer.beta1, args.exp.optimizer.beta2), \n",
    "                             eps=args.exp.optimizer.eps)\n",
    "print(\"Optimizer setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup test dataset\n",
    "from audiofolder_test import AudioFolderDatasetTest\n",
    "test_set_obj =  AudioFolderDatasetTest(dset_args=args.dset, \n",
    "                                    fs=args.exp.sample_rate*args.exp.resample_factor,\n",
    "                                    seg_len=args.exp.audio_len*args.exp.resample_factor, \n",
    "                                    num_samples=args.dset.test.num_samples)\n",
    "test_set = torch.utils.data.DataLoader(dataset=test_set_obj, batch_size=args.dset.test.batch_size,  \n",
    "                                       num_workers=args.exp.num_workers, pin_memory=True, \n",
    "                                       worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tester setup complete\n"
     ]
    }
   ],
   "source": [
    "# Setup tester\n",
    "from testing.tester import Tester\n",
    "\n",
    "tester = Tester(args=args, network=network, test_set=test_set, diff_params=diff_params, device=device)\n",
    "print(\"Tester setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_params:  186.279616 M\n",
      "trying to load a project checkpoint\n",
      "checkpoint_id None\n",
      "Missing key model_dir\n",
      "    full_key: model_dir\n",
      "    object_type=dict\n",
      "Could not resume from checkpoint\n",
      "training from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "wandb: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter:wandb: Paste an API key from your profile and hit enter:"
     ]
    }
   ],
   "source": [
    "# Setup trainer\n",
    "from training.trainer import Trainer\n",
    "trainer = Trainer(args, dset=train_set, network=network, optimizer=optimizer, diff_params=diff_parameters, tester=tester, device=device)\n",
    "print(\"Trainer setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training options:\n",
      "Network architecture:    networks.unet_cqt_oct_with_projattention_adaLN_2.Unet_CQT_oct_with_attention\n",
      "Diffusion parameterization:  diff_params.edm.EDM\n",
      "Batch size:              4\n",
      "Number of GPUs:          1\n",
      "Mixed-precision:         False\n"
     ]
    }
   ],
   "source": [
    "# Print Training related information\n",
    "print('\\nTraining options:')\n",
    "print(f'Network architecture:    {args.network.callable}')\n",
    "print(f'Diffusion parameterization:  {args.diff_params.callable}')\n",
    "print(f'Batch size:              {args.exp.batch}')\n",
    "print(f'Number of GPUs:          {1 if torch.cuda.is_available() else 0}')\n",
    "print(f'Mixed-precision:         {args.exp.use_fp16}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "trainer.training_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS371-conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
